{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear quadratic discounted cost problem\n",
    "In this live script we consider the following system\n",
    "\n",
    "$$\\dot{x}(t)=A x(t)+B u(t)+w(t), \\quad t \\in \\mathbb{R}\\geq 0,$$\n",
    "\n",
    "where $w$ is a zero-mean Gaussian white noise process with $\\mathbb{E}[w(t) \n",
    "w(t+\\tau)]=W \\delta(\\tau)$. We assume that the initial state is unknown and \n",
    "follows a Gaussian distribution with mean $\\overline{x}_0$ and variance $\\mathbb{E}\\left[\\left(x_{0}-\\bar{x}_{0}\\right)\\left(x_{0}-\\bar{x}_{0}\\right)^{\\top}\\right]=\\Theta_{0}$.  \n",
    "Moreover, the following discounted cost is considered\n",
    "\n",
    "$$\\int_{0}^{\\infty} e^{-\\alpha t}\\left(x(t)^{\\top} Q x(t)+u(t)^{\\top} R u(t)\\right) \n",
    "d t$$\n",
    "\n",
    "with a discount factor $\\alpha \\ \\ge \\ 0$. Note that when $\\alpha\\ = \\ 0$ \n",
    "and $W\\ =\\ 0$,  this boils down to a standard LQR problem. As we shall see shortly, \n",
    "it can be argued that the optimal policy for the discounted cost problem is\n",
    "\n",
    "$$u_k\\ =\\ K x_k$$\n",
    "\n",
    "where $K$ can also be obtained by solving an algebraic Ricatti equation (ARE). \n",
    "However, when $\\alpha \\ > \\ 0$, such an ARE, is different from the one for the \n",
    "case $\\alpha\\ = \\ 0$. The goal of this live script, is to compute $K$, given \n",
    "$A$, $B$, $C$, $D$, and $\\alpha$.\n",
    "\n",
    "We now justify that the optimal control policy takes a simple static linear \n",
    "state feedback form and explain how to compute the optimal gains $K$. We start \n",
    "with a finite horizon discounted cost problem with no disturbances $W =\\ 0$, \n",
    "described by\n",
    "\n",
    "$$\\min \\int_{0}^{T} e^{-\\alpha t}\\left(x(t)^{\\top} Q x(t)+u(t)^{\\top} R u(t)\\right) \n",
    "d t$$\n",
    "\n",
    "for a given horizon $T$, for the system\n",
    "\n",
    "$$\\dot{x}(t)=A x(t)+B u(t), \\quad t \\in \\mathbb{R}_{\\geq 0}$$\n",
    "\n",
    "Therefore, the HJB equation is given by\n",
    "\n",
    "$$\\min _{u} \\frac{\\partial}{\\partial t} V(t, x)+\\frac{\\partial}{\\partial x} \n",
    "V(t, x)(A x+B u)+e^{-\\alpha t} x(t)^{\\top} Q x(t)+e^{-\\alpha t} u^{\\top} R u=0$$\n",
    "\n",
    "where $V(T, x)=0$, for every $x$, is the terminal constraint. \n",
    "\n",
    "By differentiating the expression above with respect to the control input \n",
    "$u$ and setting the derivative to zero, we obtain the optimal control input \n",
    "$u$, which minimizes the HJB, equal to \n",
    "\n",
    "$$u=-e^{\\alpha t} R^{-1} B^{\\top}\\left[\\frac{\\partial}{\\partial x} V(t, x)\\right]^{\\top}.$$\n",
    "\n",
    "We will not show $V(t, x)=e^{-\\alpha t} x^{\\top} P(t) x$ satisfies the HJB \n",
    "equation. By replacing the optimal $u$ and the previous $V(x,t)$, we obtain\n",
    "\n",
    "$$-\\alpha e^{-\\alpha t} x^{\\top} P(t) x+e^{-\\alpha t} x^{\\top} \\dot{P}(t) \n",
    "x+e^{-\\alpha t} x^{\\top} P(t) A x+e^{-\\alpha t} x^{\\top} A^{\\top} P(t) x$$\n",
    "\n",
    "$$+e^{-\\alpha t} x^{\\top} Q x-e^{-\\alpha t} x^{\\top}\\left(P(t) B R^{-1} B^{\\top} \n",
    "P(t)\\right) x=0$$\n",
    "\n",
    "which holds, together with the terminal condition, if $P(t)$ satisfies\n",
    "\n",
    "$$\\dot{P}(t)=-\\left(-\\alpha P(t)+A^{\\top} P(t)+P(t) A+Q-P(t) B R^{-1} B^{\\top} \n",
    "P(t)\\right), \\quad P(T)=0.$$\n",
    "\n",
    "Then the optimal policy is $u=K(t)x$, where $K(t)=-R^{-1} B^{\\top} P(t)$. \n",
    "As $T$ converves to infinity, as in the usual case when $\\alpha=0$ , the solution \n",
    "$P(t)$ will be such that $P(0)$ converges to $P$, where $P$ is the solution \n",
    "of the following ARE: $-\\alpha P+A^{\\top} P+P A+Q-P B R^{-1} B^{\\top} P=0$. \n",
    "Then the control law converges to \n",
    "\n",
    "$$u=Kx,$$\n",
    "\n",
    "where $K=-R^{-1}B^TP$.\n",
    "\n",
    "Note that if we consider disturbances for the case of finite horizon, a similar \n",
    "reasoning to the one discussed in the lectures for the case $a=0$ allows us \n",
    "to conclude that certainty equivalence holds and the policy is the same. Since \n",
    "the exponentially decaying weighting factor makes the cost bounded even in the \n",
    "presence of disturbances we do not need to consider the average cost, simply \n",
    "taking the expect cost is enough. The policy for the infinite horizon case with \n",
    "disturbances, as in the case $a=0$, is a simple state feedback policy as described \n",
    "above.\n",
    "\n",
    "For convenience, the ARE is rearranged as $\\left(A-\\frac{\\alpha}{2} I\\right)^{\\top} \n",
    "P+P\\left(A-\\frac{\\alpha}{2} I\\right)+Q-P B R^{-1} B^{\\top} P=0$. So the discounted \n",
    "cost problem is equivalent to an undiscounted one and it can be solved by the \n",
    "`lqr` function, by noticing that matrix $A$ should be replaced by $A\\ -\\ \\frac{\\alpha}{2}I$. \n",
    "\n",
    "The problem described above, is implemented in the function `lqdiscounted`, \n",
    "which takes  $A$, $B$, $C$, $D$, and $\\alpha$ as inputs and provides the optimal \n",
    "gains $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import control\n",
    "control.use_numpy_matrix(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqdiscounted(A,B,Q,R,alpha):\n",
    "    \n",
    "    return control.lqr(A-alpha/2,B,Q,R)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs and run the function\n",
    "A = np.array([[0, 1],[ -3, 0]])\n",
    "B = np.array([[0],[1]])\n",
    "Q = np.array([[1, 0],[0, 0]])\n",
    "R = 1\n",
    "alpha = 0\n",
    "K = lqdiscounted(A,B,Q,R,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
